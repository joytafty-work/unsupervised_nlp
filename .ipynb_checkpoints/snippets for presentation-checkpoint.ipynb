{
 "metadata": {
  "name": "",
  "signature": "sha256:5e7e6364773020a311bd80eb234df99acfb7d53942a2f695643d3a0f91852157"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "file_name = './ted_mini/art_positive/5.ted'\n",
      "delim = \" \"\n",
      "with open(file_name, 'r') as f: \n",
      "    dat = f.readlines()\n",
      "    dat = map(lambda x: x.replace('_en', '').replace(\"\\n\", \"\").lower().split(delim), dat)\n",
      "\n",
      "# df = pd.DataFrame(dat).rename(columns={0:'word', 1:'count'}).sort('count', ascending=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import chain\n",
      "dat = list(chain(*dat))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "import numpy as np\n",
      "d = pd.DataFrame(list(chain(*dat))).rename(columns={0:'word'})\n",
      "d['count'] = 1\n",
      "df = d.groupby('word').agg('sum').sort('count', ascending=False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>word</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>,</th>\n",
        "      <td> 325</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>.</th>\n",
        "      <td> 188</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>and</th>\n",
        "      <td> 147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td> 133</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>to</th>\n",
        "      <td> 118</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>that</th>\n",
        "      <td> 107</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>a</th>\n",
        "      <td>  98</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>of</th>\n",
        "      <td>  97</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>i</th>\n",
        "      <td>  87</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>this</th>\n",
        "      <td>  85</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>we</th>\n",
        "      <td>  79</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>it</th>\n",
        "      <td>  77</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>you</th>\n",
        "      <td>  74</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>in</th>\n",
        "      <td>  69</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>is</th>\n",
        "      <td>  62</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>'s</th>\n",
        "      <td>  56</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>they</th>\n",
        "      <td>  49</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>\"</th>\n",
        "      <td>  46</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>--</th>\n",
        "      <td>  40</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>what</th>\n",
        "      <td>  35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>was</th>\n",
        "      <td>  33</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>with</th>\n",
        "      <td>  32</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>'re</th>\n",
        "      <td>  29</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>have</th>\n",
        "      <td>  29</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>about</th>\n",
        "      <td>  28</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>cars</th>\n",
        "      <td>  27</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>n't</th>\n",
        "      <td>  26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>all</th>\n",
        "      <td>  25</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>are</th>\n",
        "      <td>  25</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>so</th>\n",
        "      <td>  24</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>order</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>conditions</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>opinions</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>holders</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>hip</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>help</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>dr.</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>co</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>coffee</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>collusion</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>prince</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>priest</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>coming</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>pressure</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>commitment</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>henry</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>company</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>pop</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>physical</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>pollution</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>pollute</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>pole</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>compare</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>platonic</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>plane</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>places</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>pin</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>pictures</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>picture</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>postcard</th>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>799 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "            count\n",
        "word             \n",
        ",             325\n",
        ".             188\n",
        "and           147\n",
        "the           133\n",
        "to            118\n",
        "that          107\n",
        "a              98\n",
        "of             97\n",
        "i              87\n",
        "this           85\n",
        "we             79\n",
        "it             77\n",
        "you            74\n",
        "in             69\n",
        "is             62\n",
        "'s             56\n",
        "they           49\n",
        "\"              46\n",
        "--             40\n",
        "what           35\n",
        "was            33\n",
        "with           32\n",
        "'re            29\n",
        "have           29\n",
        "about          28\n",
        "cars           27\n",
        "n't            26\n",
        "all            25\n",
        "are            25\n",
        "so             24\n",
        "...           ...\n",
        "order           1\n",
        "conditions      1\n",
        "opinions        1\n",
        "holders         1\n",
        "hip             1\n",
        "help            1\n",
        "dr.             1\n",
        "co              1\n",
        "coffee          1\n",
        "collusion       1\n",
        "prince          1\n",
        "priest          1\n",
        "coming          1\n",
        "pressure        1\n",
        "commitment      1\n",
        "henry           1\n",
        "company         1\n",
        "pop             1\n",
        "physical        1\n",
        "pollution       1\n",
        "pollute         1\n",
        "pole            1\n",
        "compare         1\n",
        "platonic        1\n",
        "plane           1\n",
        "places          1\n",
        "pin             1\n",
        "pictures        1\n",
        "picture         1\n",
        "postcard        1\n",
        "\n",
        "[799 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open ('./5.ted_int_output', 'w') as g:  \n",
      "    for i in range(4):\n",
      "        g.write(' '.join(dat[i]) + '\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"what i want to talk about is , as background , is the idea that cars are art .\n",
      "this is actually quite meaningful to me , because car designers tend to be a little bit low on the totem pole -- we do n't do coffee table books with just one lamp inside of it -- and cars are thought so much as a product that it 's a little bit difficult to get into the aesthetic side under the same sort of terminology that one would discuss art .\n",
      "and so cars , as art , brings it into an emotional plane -- if you accept that -- that you have to deal with on the same level you would with art with a capital a.\n",
      "now at this point you 're going to see a picture of michelangelo .\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "import pandas as pd\n",
      "cv = CountVectorizer()\n",
      "vec = cv.fit(dat)\n",
      "\n",
      "df = pd.DataFrame(\n",
      "    vec.vocabulary_.items())\n",
      "        .rename(columns={0:'word', 1:'count'})\n",
      "        .sort('count', ascending=0)\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tf(t, doc):\n",
      "    if type(doc) == list: \n",
      "        return float(doc.count(t))/float(len(doc))\n",
      "    elif type(doc) == str: \n",
      "        doc = text_to_bagofwords(doc)\n",
      "        return float(doc.count(t))/float(len(doc))\n",
      "    else: \n",
      "        return NaN\n",
      "\n",
      "def idf(t, corpus):\n",
      "    df = 0\n",
      "    for doc in corpus: \n",
      "        if doc.count(t) > 0: \n",
      "            df += 1\n",
      "    return float(len(corpus))/float(df + 0.01)\n",
      "\n",
      "def tfidf(t, doc, corpus):\n",
      "    return tf(t, doc)*idf(t, corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "# vec = TfidfVectorizer()\n",
      "# tfidf = vec.fit_transform(dat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import lda\n",
      "import lda.datasets\n",
      "X = lda.datasets.load_reuters()\n",
      "vocab = lda.datasets.load_reuters_vocab()\n",
      "titles = lda.datasets.load_reuters_titles()\n",
      "model = lda.LDA(n_topics=20, n_iter=1500, random_state=1)\n",
      "model.fit(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import lda\n",
      "model = lda.LDA(n_topics=20, n_iter=1500, random_state=1)\n",
      "model.fit(X)\n",
      "ntop=10\n",
      "for i, topic_dist in enumerate(model.topic_word_[:ntop]):\n",
      "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(ntop+1):-1]\n",
      "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "<lda.lda.LDA instance at 0x10640c170>"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc_topic = model.doc_topic_\n",
      "for i in range(10):\n",
      "    print(\"{} (top topic: {})\".format(titles[i], doc_topic[i].argmax()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 UK: Prince Charles spearheads British royal revolution. LONDON 1996-08-20 (top topic: 8)\n",
        "1 GERMANY: Historic Dresden church rising from WW2 ashes. DRESDEN, Germany 1996-08-21 (top topic: 13)\n",
        "2 INDIA: Mother Teresa's condition said still unstable. CALCUTTA 1996-08-23 (top topic: 14)\n",
        "3 UK: Palace warns British weekly over Charles pictures. LONDON 1996-08-25 (top topic: 8)\n",
        "4 INDIA: Mother Teresa, slightly stronger, blesses nuns. CALCUTTA 1996-08-25 (top topic: 14)\n",
        "5 INDIA: Mother Teresa's condition unchanged, thousands pray. CALCUTTA 1996-08-25 (top topic: 14)\n",
        "6 INDIA: Mother Teresa shows signs of strength, blesses nuns. CALCUTTA 1996-08-26 (top topic: 14)\n",
        "7 INDIA: Mother Teresa's condition improves, many pray. CALCUTTA, India 1996-08-25 (top topic: 14)\n",
        "8 INDIA: Mother Teresa improves, nuns pray for \"miracle\". CALCUTTA 1996-08-26 (top topic: 14)\n",
        "9 UK: Charles under fire over prospect of Queen Camilla. LONDON 1996-08-26 (top topic: 8)\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import stopwords\n",
      "stoplist = stopwords.words('english')\n",
      "texts = map(lambda y: \n",
      "        filter(lambda x: len(x) > 2, y), \n",
      "        texts)\n",
      "dictionary = corpora.Dictionary(texts)\n",
      "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist\n",
      "            if stopword in dictionary.token2id]\n",
      "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq == 1]\n",
      "dictionary.filter_tokens(stop_ids + once_ids) \n",
      "dictionary.compactify()\n",
      "dictionary.save(os.path.join(outputdir, 'artsci_positive_corpus.dict'))\n",
      "\n",
      "artsci_corpus = [dictionary.doc2bow(text) for text in texts if text not in stoplist and sum(map(lambda x: int(not str.isdigit(x)), list(text))) < 2]\n",
      "corpora.MmCorpus.serialize(os.path.join(outputdir, 'artsci_positive_corpus.mm'), artsci_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "'int' object is not iterable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-277-90dda69e2508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0monce_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokenid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocfreq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdocfreq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m short_ids = [dictionary.token2id[short_word] for short_word in dictionary.dfs.itervalues()\n\u001b[0;32m---> 11\u001b[0;31m             if sum(map(lambda x: int(not str.isdigit(x)), list(short_word))) < 2]\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_ids\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0monce_ids\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshort_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompactify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
       ]
      }
     ],
     "prompt_number": 277
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.models.ldamodel import LdaModel\n",
      "lda = LdaModel(corpus=artsci_corpus, id2word=dictionary, num_topics=15, update_every=10, chunksize=10, passes=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
       ]
      }
     ],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = map(lambda y: \n",
      "        filter(lambda x: len(x) > 2, y), \n",
      "        texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 259
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 276,
       "text": [
        "100"
       ]
      }
     ],
     "prompt_number": 276
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(once_ids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 191,
       "text": [
        "7456"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}